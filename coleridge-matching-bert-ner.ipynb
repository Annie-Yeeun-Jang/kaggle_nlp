{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook gives a simple combination of literal matching and Named Entity Recognition using BERT (base model from huggingface).\n\nThe training phase of the BERT model was done in another kernel: Pytorch BERT for Named Entity Recognition.(엄청 오래걸리는 코드)\n\nBERT NER 사용법은 https://mezzaninex.tistory.com/entry/AI-BERT%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-NER-%EC%A0%81%EC%9A%A9-%EB%B0%A9%EB%B2%95-%EC%A0%95%EB%A6%AC 참고!","metadata":{}},{"cell_type":"code","source":"MAX_SAMPLE = None # set a small number for experimentation, set None for production.","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:20:40.121355Z","iopub.execute_input":"2021-05-23T15:20:40.121899Z","iopub.status.idle":"2021-05-23T15:20:40.129618Z","shell.execute_reply.started":"2021-05-23T15:20:40.121717Z","shell.execute_reply":"2021-05-23T15:20:40.127914Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Install packages\n외부 input 가져와서 설치하기","metadata":{}},{"cell_type":"code","source":"!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:20:40.137097Z","iopub.execute_input":"2021-05-23T15:20:40.137451Z","iopub.status.idle":"2021-05-23T15:22:16.845007Z","shell.execute_reply.started":"2021-05-23T15:20:40.137421Z","shell.execute_reply":"2021-05-23T15:22:16.843786Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/coleridge-packages/packages/datasets\nProcessing /kaggle/input/coleridge-packages/packages/datasets/datasets-1.5.0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\nRequirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/huggingface_hub-0.0.7-py3-none-any.whl\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.3.0)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/tqdm-4.49.0-py2.py3-none-any.whl\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.1.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\nProcessing /kaggle/input/coleridge-packages/packages/datasets/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2020.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\nInstalling collected packages: tqdm, xxhash, huggingface-hub, datasets\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.55.1\n    Uninstalling tqdm-4.55.1:\n      Successfully uninstalled tqdm-4.55.1\nSuccessfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\nProcessing /kaggle/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (1.19.5)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (0.24.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (2.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.5.4)\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nProcessing /kaggle/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\nInstalling collected packages: tokenizers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.9.4\n    Uninstalling tokenizers-0.9.4:\n      Successfully uninstalled tokenizers-0.9.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntransformers 4.2.2 requires tokenizers==0.9.4, but you have tokenizers 0.10.1 which is incompatible.\u001b[0m\nSuccessfully installed tokenizers-0.10.1\nProcessing /kaggle/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.10.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (20.8)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.0.43)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2020.11.13)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.0.12)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.3.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (1.19.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (4.49.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.7.4.3)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (1.26.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.2.2\n    Uninstalling transformers-4.2.2:\n      Successfully uninstalled transformers-4.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.0.1 requires transformers<4.3,>=4.1, but you have transformers 4.5.0.dev0 which is incompatible.\u001b[0m\nSuccessfully installed transformers-4.5.0.dev0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport time\nimport datetime\nimport random\nimport glob\nimport importlib\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nrandom.seed(123)\nnp.random.seed(456)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T15:22:16.847978Z","iopub.execute_input":"2021-05-23T15:22:16.848538Z","iopub.status.idle":"2021-05-23T15:22:17.683076Z","shell.execute_reply.started":"2021-05-23T15:22:16.848445Z","shell.execute_reply":"2021-05-23T15:22:17.682103Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\ntrain = pd.read_csv(train_path)\ntrain = train[:MAX_SAMPLE]\n\npaper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\npapers = {}\nfor paper_id in train['Id'].unique():\n    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:22:17.684660Z","iopub.execute_input":"2021-05-23T15:22:17.685105Z","iopub.status.idle":"2021-05-23T15:23:55.497846Z","shell.execute_reply.started":"2021-05-23T15:22:17.685059Z","shell.execute_reply":"2021-05-23T15:23:55.496448Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sample_submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\nsample_submission = pd.read_csv(sample_submission_path)\n\npaper_test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\nfor paper_id in sample_submission['Id']:\n    with open(f'{paper_test_folder}/{paper_id}.json', 'r') as f:\n        paper = json.load(f)\n        papers[paper_id] = paper","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.499847Z","iopub.execute_input":"2021-05-23T15:23:55.500269Z","iopub.status.idle":"2021-05-23T15:23:55.542116Z","shell.execute_reply.started":"2021-05-23T15:23:55.500228Z","shell.execute_reply":"2021-05-23T15:23:55.540877Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Literal matching","metadata":{}},{"cell_type":"markdown","source":"### Create a knowledge bank","metadata":{}},{"cell_type":"code","source":"all_labels = set()\n\nfor label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n    all_labels.add(str(label_1).lower())\n    all_labels.add(str(label_2).lower())\n    all_labels.add(str(label_3).lower())\n    \nprint(f'No. different labels: {len(all_labels)}')  #dataset title, label, cleaned label 에 있는 모든 라벨 종류를 다 합침","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.547955Z","iopub.execute_input":"2021-05-23T15:23:55.548266Z","iopub.status.idle":"2021-05-23T15:23:55.622514Z","shell.execute_reply.started":"2021-05-23T15:23:55.548236Z","shell.execute_reply":"2021-05-23T15:23:55.621098Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"No. different labels: 180\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Matching on test data\n베이스라인처럼 단순 매칭 있으면 일단 포함.","metadata":{}},{"cell_type":"code","source":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\ndef totally_clean_text(txt):\n    txt = clean_text(txt)\n    txt = re.sub(' +', ' ', txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.626160Z","iopub.execute_input":"2021-05-23T15:23:55.626803Z","iopub.status.idle":"2021-05-23T15:23:55.633789Z","shell.execute_reply.started":"2021-05-23T15:23:55.626754Z","shell.execute_reply":"2021-05-23T15:23:55.632468Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"literal_preds = []\n\nfor paper_id in sample_submission['Id']:\n    paper = papers[paper_id]\n    text_1 = '. '.join(section['text'] for section in paper).lower()\n    text_2 = totally_clean_text(text_1)\n    \n    labels = set()\n    for label in all_labels:\n        if label in text_1 or label in text_2:\n            labels.add(clean_text(label))\n    \n    literal_preds.append('|'.join(labels))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.637368Z","iopub.execute_input":"2021-05-23T15:23:55.638046Z","iopub.status.idle":"2021-05-23T15:23:55.767909Z","shell.execute_reply.started":"2021-05-23T15:23:55.637995Z","shell.execute_reply":"2021-05-23T15:23:55.766592Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"literal_preds  #baseline이랑 똑같음 !!","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.769730Z","iopub.execute_input":"2021-05-23T15:23:55.770237Z","iopub.status.idle":"2021-05-23T15:23:55.780590Z","shell.execute_reply.started":"2021-05-23T15:23:55.770194Z","shell.execute_reply":"2021-05-23T15:23:55.779071Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['alzheimer s disease neuroimaging initiative adni|adni',\n 'nces common core of data|trends in international mathematics and science study|common core of data',\n 'noaa storm surge inundation|sea lake and overland surges from hurricanes|slosh model',\n 'rural urban continuum codes']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Bert prediction","metadata":{"trusted":true}},{"cell_type":"markdown","source":"### Paths and Hyperparameters","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 256 # max no. words for each sentence.  => 512까지 늘려도 되는듯함. 여기서는 64로 했음\nOVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n\nPREDICT_BATCH = 64000 \n\nPRETRAINED_PATH = '../input/coleridge-bert-models/output'\nTEST_INPUT_SAVE_PATH = './input_data'\nTEST_NER_DATA_FILE = 'test_ner_input.json'\nTRAIN_PATH = '../input/coleridge-bert-models/train_ner.json'\nVAL_PATH = '../input/coleridge-bert-models/train_ner.json'\n\nPREDICTION_SAVE_PATH = './pred'\nPREDICTION_FILE = 'test_predictions.txt'","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.783690Z","iopub.execute_input":"2021-05-23T15:23:55.784252Z","iopub.status.idle":"2021-05-23T15:23:55.792914Z","shell.execute_reply.started":"2021-05-23T15:23:55.784176Z","shell.execute_reply":"2021-05-23T15:23:55.791631Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Transform data to NER format","metadata":{}},{"cell_type":"markdown","source":"Group by publication, training labels should have the same form as expected output.\n\n딕셔너리에 토큰 : 태그 형식으로 바꾸어 넣는듯","metadata":{}},{"cell_type":"code","source":"train = train.groupby('Id').agg({\n    'pub_title': 'first',\n    'dataset_title': '|'.join,\n    'dataset_label': '|'.join,\n    'cleaned_label': '|'.join\n}).reset_index()\n\nprint(f'No. grouped training rows: {len(train)}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:55.795515Z","iopub.execute_input":"2021-05-23T15:23:55.796122Z","iopub.status.idle":"2021-05-23T15:23:56.260683Z","shell.execute_reply.started":"2021-05-23T15:23:55.796074Z","shell.execute_reply":"2021-05-23T15:23:56.259384Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"No. grouped training rows: 14316\n","output_type":"stream"}]},{"cell_type":"code","source":"def clean_training_text(txt):\n    \"\"\"\n    similar to the default clean_text function but without lowercasing.\n    \"\"\"\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n\n\ndef shorten_sentences(sentences):  #문장이 max len 넘을 경우에 처리 방법\n    short_sentences = []\n    for sentence in sentences:\n        words = sentence.split()\n        if len(words) > MAX_LENGTH:\n            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n        else:\n            short_sentences.append(sentence)\n    return short_sentences","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:56.262505Z","iopub.execute_input":"2021-05-23T15:23:56.263239Z","iopub.status.idle":"2021-05-23T15:23:56.273156Z","shell.execute_reply.started":"2021-05-23T15:23:56.263194Z","shell.execute_reply":"2021-05-23T15:23:56.271684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_rows = [] # test data in NER format\npaper_length = [] # store the number of sentences each paper has\n\nfor paper_id in sample_submission['Id']:\n    # load paper\n    paper = papers[paper_id]\n    \n    # extract sentences\n    sentences = [clean_training_text(sentence) for section in paper \n                 for sentence in section['text'].split('.')]                \n    sentences = shorten_sentences(sentences) # make sentences short\n    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n    #sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study','from'])]  #단어들 포함하는 문장이 라벨 7-80% 담당\n        \n    # collect all sentences in json\n    for sentence in sentences:\n        sentence_words = sentence.split()\n        dummy_tags = ['O']*len(sentence_words)\n        test_rows.append({'tokens' : sentence_words, 'tags' : dummy_tags})\n    \n    # track which sentence belongs to which data point\n    paper_length.append(len(sentences))\n    \nprint(f'total number of sentences: {len(test_rows)}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:56.275324Z","iopub.execute_input":"2021-05-23T15:23:56.275933Z","iopub.status.idle":"2021-05-23T15:23:56.341993Z","shell.execute_reply.started":"2021-05-23T15:23:56.275881Z","shell.execute_reply":"2021-05-23T15:23:56.340520Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"total number of sentences: 2283\n","output_type":"stream"}]},{"cell_type":"markdown","source":"결국은 세어보려고 두가지 방법으로 묶어본거네","metadata":{}},{"cell_type":"markdown","source":"### Do predict and collect results","metadata":{}},{"cell_type":"code","source":"os.environ[\"MODEL_PATH\"] = f\"{PRETRAINED_PATH}\"\nos.environ[\"TRAIN_FILE\"] = f\"{TRAIN_PATH}\"\nos.environ[\"VALIDATION_FILE\"] = f\"{VAL_PATH}\"\nos.environ[\"TEST_FILE\"] = f\"{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}\"\nos.environ[\"OUTPUT_DIR\"] = f\"{PREDICTION_SAVE_PATH}\"","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:56.343626Z","iopub.execute_input":"2021-05-23T15:23:56.344087Z","iopub.status.idle":"2021-05-23T15:23:56.352509Z","shell.execute_reply.started":"2021-05-23T15:23:56.344049Z","shell.execute_reply":"2021-05-23T15:23:56.350498Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# copy my_seqeval.py to the working directory because the input directory is non-writable\n!cp /kaggle/input/coleridge-packages/my_seqeval.py ./\n\n# make necessart directories and files\nos.makedirs(TEST_INPUT_SAVE_PATH, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:23:56.354586Z","iopub.execute_input":"2021-05-23T15:23:56.355468Z","iopub.status.idle":"2021-05-23T15:23:57.167915Z","shell.execute_reply.started":"2021-05-23T15:23:56.355416Z","shell.execute_reply":"2021-05-23T15:23:57.166267Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def bert_predict():\n    !python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n    --model_name_or_path \"$MODEL_PATH\" \\\n    --train_file \"$TRAIN_FILE\" \\\n    --validation_file \"$VALIDATION_FILE\" \\\n    --test_file \"$TEST_FILE\" \\\n    --output_dir \"$OUTPUT_DIR\" \\\n    --report_to 'none' \\\n    --seed 123 \\\n    --do_predict","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:28:18.709416Z","iopub.execute_input":"2021-05-23T15:28:18.709840Z","iopub.status.idle":"2021-05-23T15:28:18.718729Z","shell.execute_reply.started":"2021-05-23T15:28:18.709804Z","shell.execute_reply":"2021-05-23T15:28:18.715052Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#BERT Training 실행하는 부분 !!\n\nbert_outputs = []\n\nfor batch_begin in range(0, len(test_rows), PREDICT_BATCH):\n    # write data rows to input file\n    with open(f'{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}', 'w') as f:\n        for row in test_rows[batch_begin:batch_begin+PREDICT_BATCH]:\n            json.dump(row, f)\n            f.write('\\n')\n    \n    # remove output dir\n    !rm -r \"$OUTPUT_DIR\"\n    \n    # do predict\n    bert_predict()\n    \n    # read predictions\n    with open(f'{PREDICTION_SAVE_PATH}/{PREDICTION_FILE}') as f:\n        this_preds = f.read().split('\\n')[:-1]\n        bert_outputs += [pred.split() for pred in this_preds]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:28:21.628862Z","iopub.execute_input":"2021-05-23T15:28:21.629248Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"rm: cannot remove './pred': No such file or directory\n2021-05-23 15:28:28.106915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\nDownloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-a1bef6b4593570cd/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\nDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a1bef6b4593570cd/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n[INFO|configuration_utils.py:470] 2021-05-23 15:29:27,766 >> loading configuration file ../input/coleridge-bert-models/output/config.json\n[INFO|configuration_utils.py:508] 2021-05-23 15:29:27,767 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-cased\",\n  \"architectures\": [\n    \"BertForTokenClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"finetuning_task\": \"ner\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.5.0.dev0\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 28996\n}\n\n[INFO|configuration_utils.py:470] 2021-05-23 15:29:27,768 >> loading configuration file ../input/coleridge-bert-models/output/config.json\n[INFO|configuration_utils.py:508] 2021-05-23 15:29:27,768 >> Model config BertConfig {\n  \"_name_or_path\": \"bert-base-cased\",\n  \"architectures\": [\n    \"BertForTokenClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"finetuning_task\": \"ner\",\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.5.0.dev0\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 28996\n}\n\n[INFO|tokenization_utils_base.py:1637] 2021-05-23 15:29:27,774 >> Didn't find file ../input/coleridge-bert-models/output/tokenizer.json. We won't load it.\n[INFO|tokenization_utils_base.py:1637] 2021-05-23 15:29:27,775 >> Didn't find file ../input/coleridge-bert-models/output/added_tokens.json. We won't load it.\n[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:29:27,782 >> loading file ../input/coleridge-bert-models/output/vocab.txt\n[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:29:27,782 >> loading file None\n[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:29:27,782 >> loading file None\n[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:29:27,782 >> loading file ../input/coleridge-bert-models/output/special_tokens_map.json\n[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:29:27,782 >> loading file ../input/coleridge-bert-models/output/tokenizer_config.json\n[INFO|modeling_utils.py:1049] 2021-05-23 15:29:27,867 >> loading weights file ../input/coleridge-bert-models/output/pytorch_model.bin\n[INFO|modeling_utils.py:1167] 2021-05-23 15:29:38,350 >> All model checkpoint weights were used when initializing BertForTokenClassification.\n\n[INFO|modeling_utils.py:1176] 2021-05-23 15:29:38,350 >> All the weights of BertForTokenClassification were initialized from the model checkpoint at ../input/coleridge-bert-models/output.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.71ba/s]\n[INFO|trainer.py:485] 2021-05-23 15:29:47,417 >> The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags.\n[INFO|trainer.py:1817] 2021-05-23 15:29:47,419 >> ***** Running Prediction *****\n[INFO|trainer.py:1818] 2021-05-23 15:29:47,419 >>   Num examples = 2283\n[INFO|trainer.py:1819] 2021-05-23 15:29:47,420 >>   Batch size = 8\n  0%|                                                   | 0/286 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"### Restore Dataset labels from predictions","metadata":{}},{"cell_type":"code","source":"# get test sentences\ntest_sentences = [row['tokens'] for row in test_rows]\n\ndel test_rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_dataset_labels = [] # store all dataset labels for each publication\n\nfor length in paper_length:\n    labels = set()\n    for sentence, pred in zip(test_sentences[:length], bert_outputs[:length]):\n        curr_phrase = ''\n        for word, tag in zip(sentence, pred):\n            if tag == 'B': # start a new phrase\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n                curr_phrase = word\n            elif tag == 'I' and curr_phrase: # continue the phrase\n                curr_phrase += ' ' + word\n            else: # end last phrase (if any)\n                if curr_phrase:\n                    labels.add(curr_phrase)\n                    curr_phrase = ''\n        # check if the label is the suffix of the sentence\n        if curr_phrase:\n            labels.add(curr_phrase)\n            curr_phrase = ''\n    \n    # record dataset labels for this publication\n    bert_dataset_labels.append(labels)\n    \n    del test_sentences[:length], bert_outputs[:length]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_dataset_labels   #문제는 이것들이 다 베이스라인에 이미 있는 것들... => 그래서 점수 똑같이 나오는거네..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"data, study, from 포함되는 문장만 뽑는거 줄이는 코드 없애니까 맨 마지막 id 부분이 BERT에서도 뭔가가 나오네..\n\n문장 max 길이 256으로 늘려봐도 결과 똑같음","metadata":{}},{"cell_type":"markdown","source":"### Filter based on Jaccard score and clean","metadata":{}},{"cell_type":"code","source":"def jaccard_similarity(s1, s2):\n    l1 = s1.split(\" \")\n    l2 = s2.split(\" \")    \n    intersection = len(list(set(l1).intersection(l2)))\n    union = (len(l1) + len(l2)) - intersection\n    return float(intersection) / union\n\nfiltered_bert_labels = []\n\nfor labels in bert_dataset_labels:\n    filtered = []\n    \n    for label in sorted(labels, key=len):\n        label = clean_text(label)\n        if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered):\n            filtered.append(label)\n    \n    filtered_bert_labels.append('|'.join(filtered))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_bert_labels[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aggregate final predictions and write submission file","metadata":{}},{"cell_type":"code","source":"final_predictions = []\nfor literal_match, bert_pred in zip(literal_preds, filtered_bert_labels):\n    if literal_match:\n        #final_predictions.append(literal_match)\n        pass\n    else:\n        final_predictions.append(bert_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['PredictionString'] = final_predictions\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(f'submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}