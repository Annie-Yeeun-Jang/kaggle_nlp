{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028536,
     "end_time": "2021-05-23T15:42:59.525971",
     "exception": false,
     "start_time": "2021-05-23T15:42:59.497435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook gives a simple combination of literal matching and Named Entity Recognition using BERT (base model from huggingface).\n",
    "\n",
    "The training phase of the BERT model was done in another kernel: Pytorch BERT for Named Entity Recognition.(엄청 오래걸리는 코드)\n",
    "\n",
    "BERT NER 사용법은 https://mezzaninex.tistory.com/entry/AI-BERT%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-NER-%EC%A0%81%EC%9A%A9-%EB%B0%A9%EB%B2%95-%EC%A0%95%EB%A6%AC 참고!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:42:59.588704Z",
     "iopub.status.busy": "2021-05-23T15:42:59.587408Z",
     "iopub.status.idle": "2021-05-23T15:42:59.591422Z",
     "shell.execute_reply": "2021-05-23T15:42:59.592008Z",
     "shell.execute_reply.started": "2021-05-23T15:20:40.121717Z"
    },
    "papermill": {
     "duration": 0.038434,
     "end_time": "2021-05-23T15:42:59.592405",
     "exception": false,
     "start_time": "2021-05-23T15:42:59.553971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SAMPLE = None # set a small number for experimentation, set None for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027846,
     "end_time": "2021-05-23T15:42:59.653602",
     "exception": false,
     "start_time": "2021-05-23T15:42:59.625756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install packages\n",
    "외부 input 가져와서 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:42:59.718522Z",
     "iopub.status.busy": "2021-05-23T15:42:59.717610Z",
     "iopub.status.idle": "2021-05-23T15:44:35.030573Z",
     "shell.execute_reply": "2021-05-23T15:44:35.029969Z",
     "shell.execute_reply.started": "2021-05-23T15:20:40.137421Z"
    },
    "papermill": {
     "duration": 95.349754,
     "end_time": "2021-05-23T15:44:35.030737",
     "exception": false,
     "start_time": "2021-05-23T15:42:59.680983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/coleridge-packages/packages/datasets\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/datasets-1.5.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.3.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/tqdm-4.49.0-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/huggingface_hub-0.0.7-py3-none-any.whl\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.1.5)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.5)\r\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.2)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2020.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, datasets\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.55.1\r\n",
      "    Uninstalling tqdm-4.55.1:\r\n",
      "      Successfully uninstalled tqdm-4.55.1\r\n",
      "Successfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\r\n",
      "Processing /kaggle/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (0.24.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (1.19.5)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.5.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (2.1.0)\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n",
      "Processing /kaggle/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Installing collected packages: tokenizers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.9.4\r\n",
      "    Uninstalling tokenizers-0.9.4:\r\n",
      "      Successfully uninstalled tokenizers-0.9.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "transformers 4.2.2 requires tokenizers==0.9.4, but you have tokenizers 0.10.1 which is incompatible.\u001b[0m\r\n",
      "Successfully installed tokenizers-0.10.1\r\n",
      "Processing /kaggle/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.0.43)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.10.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (20.8)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2.25.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.0.12)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2020.11.13)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (4.49.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (1.19.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.7.4.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (1.26.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.2.2\r\n",
      "    Uninstalling transformers-4.2.2:\r\n",
      "      Successfully uninstalled transformers-4.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 2.0.1 requires transformers<4.3,>=4.1, but you have transformers 4.5.0.dev0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed transformers-4.5.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n",
    "!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n",
    "!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035384,
     "end_time": "2021-05-23T15:44:35.103848",
     "exception": false,
     "start_time": "2021-05-23T15:44:35.068464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-23T15:44:35.185687Z",
     "iopub.status.busy": "2021-05-23T15:44:35.182895Z",
     "iopub.status.idle": "2021-05-23T15:44:35.997534Z",
     "shell.execute_reply": "2021-05-23T15:44:35.996651Z",
     "shell.execute_reply.started": "2021-05-23T15:22:16.848445Z"
    },
    "papermill": {
     "duration": 0.857473,
     "end_time": "2021-05-23T15:44:35.997678",
     "exception": false,
     "start_time": "2021-05-23T15:44:35.140205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035945,
     "end_time": "2021-05-23T15:44:36.070179",
     "exception": false,
     "start_time": "2021-05-23T15:44:36.034234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:44:36.150728Z",
     "iopub.status.busy": "2021-05-23T15:44:36.150076Z",
     "iopub.status.idle": "2021-05-23T15:46:06.474099Z",
     "shell.execute_reply": "2021-05-23T15:46:06.475341Z",
     "shell.execute_reply.started": "2021-05-23T15:22:17.685059Z"
    },
    "papermill": {
     "duration": 90.36922,
     "end_time": "2021-05-23T15:46:06.475586",
     "exception": false,
     "start_time": "2021-05-23T15:44:36.106366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "train = train[:MAX_SAMPLE]\n",
    "\n",
    "paper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\n",
    "papers = {}\n",
    "for paper_id in train['Id'].unique():\n",
    "    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n",
    "        paper = json.load(f)\n",
    "        papers[paper_id] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:06.562843Z",
     "iopub.status.busy": "2021-05-23T15:46:06.561850Z",
     "iopub.status.idle": "2021-05-23T15:46:06.597543Z",
     "shell.execute_reply": "2021-05-23T15:46:06.596905Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.500228Z"
    },
    "papermill": {
     "duration": 0.082118,
     "end_time": "2021-05-23T15:46:06.597677",
     "exception": false,
     "start_time": "2021-05-23T15:46:06.515559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "paper_test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\n",
    "for paper_id in sample_submission['Id']:\n",
    "    with open(f'{paper_test_folder}/{paper_id}.json', 'r') as f:\n",
    "        paper = json.load(f)\n",
    "        papers[paper_id] = paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037594,
     "end_time": "2021-05-23T15:46:06.674697",
     "exception": false,
     "start_time": "2021-05-23T15:46:06.637103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Literal matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039221,
     "end_time": "2021-05-23T15:46:06.752025",
     "exception": false,
     "start_time": "2021-05-23T15:46:06.712804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create a knowledge bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:06.843454Z",
     "iopub.status.busy": "2021-05-23T15:46:06.842099Z",
     "iopub.status.idle": "2021-05-23T15:46:06.903602Z",
     "shell.execute_reply": "2021-05-23T15:46:06.904157Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.548236Z"
    },
    "papermill": {
     "duration": 0.11265,
     "end_time": "2021-05-23T15:46:06.904319",
     "exception": false,
     "start_time": "2021-05-23T15:46:06.791669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. different labels: 180\n"
     ]
    }
   ],
   "source": [
    "all_labels = set()\n",
    "\n",
    "for label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n",
    "    all_labels.add(str(label_1).lower())\n",
    "    all_labels.add(str(label_2).lower())\n",
    "    all_labels.add(str(label_3).lower())\n",
    "    \n",
    "print(f'No. different labels: {len(all_labels)}')  #dataset title, label, cleaned label 에 있는 모든 라벨 종류를 다 합침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040598,
     "end_time": "2021-05-23T15:46:06.986335",
     "exception": false,
     "start_time": "2021-05-23T15:46:06.945737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Matching on test data\n",
    "베이스라인처럼 단순 매칭 있으면 일단 포함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:07.076457Z",
     "iopub.status.busy": "2021-05-23T15:46:07.074269Z",
     "iopub.status.idle": "2021-05-23T15:46:07.077625Z",
     "shell.execute_reply": "2021-05-23T15:46:07.078175Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.626754Z"
    },
    "papermill": {
     "duration": 0.050152,
     "end_time": "2021-05-23T15:46:07.078326",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.028174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n",
    "\n",
    "def totally_clean_text(txt):\n",
    "    txt = clean_text(txt)\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:07.250130Z",
     "iopub.status.busy": "2021-05-23T15:46:07.209874Z",
     "iopub.status.idle": "2021-05-23T15:46:07.281650Z",
     "shell.execute_reply": "2021-05-23T15:46:07.281084Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.637995Z"
    },
    "papermill": {
     "duration": 0.163167,
     "end_time": "2021-05-23T15:46:07.281796",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.118629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "literal_preds = []\n",
    "\n",
    "for paper_id in sample_submission['Id']:\n",
    "    paper = papers[paper_id]\n",
    "    text_1 = '. '.join(section['text'] for section in paper).lower()\n",
    "    text_2 = totally_clean_text(text_1)\n",
    "    \n",
    "    labels = set()\n",
    "    for label in all_labels:\n",
    "        if label in text_1 or label in text_2:\n",
    "            labels.add(clean_text(label))\n",
    "    \n",
    "    literal_preds.append('|'.join(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:07.362503Z",
     "iopub.status.busy": "2021-05-23T15:46:07.361649Z",
     "iopub.status.idle": "2021-05-23T15:46:07.369042Z",
     "shell.execute_reply": "2021-05-23T15:46:07.368406Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.770194Z"
    },
    "papermill": {
     "duration": 0.051008,
     "end_time": "2021-05-23T15:46:07.369214",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.318206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alzheimer s disease neuroimaging initiative adni|adni',\n",
       " 'nces common core of data|common core of data|trends in international mathematics and science study',\n",
       " 'noaa storm surge inundation|slosh model|sea lake and overland surges from hurricanes',\n",
       " 'rural urban continuum codes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_preds  #baseline이랑 똑같음 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035202,
     "end_time": "2021-05-23T15:46:07.441892",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.406690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bert prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035789,
     "end_time": "2021-05-23T15:46:07.514209",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.478420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Paths and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:07.622703Z",
     "iopub.status.busy": "2021-05-23T15:46:07.620072Z",
     "iopub.status.idle": "2021-05-23T15:46:07.624172Z",
     "shell.execute_reply": "2021-05-23T15:46:07.625158Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.784176Z"
    },
    "papermill": {
     "duration": 0.074426,
     "end_time": "2021-05-23T15:46:07.625417",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.550991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256 # max no. words for each sentence.  => 512까지 늘려도 되는듯함. 여기서는 64로 했음\n",
    "OVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n",
    "\n",
    "PREDICT_BATCH = 64000 \n",
    "\n",
    "PRETRAINED_PATH = '../input/coleridge-bert-models/output'\n",
    "TEST_INPUT_SAVE_PATH = './input_data'\n",
    "TEST_NER_DATA_FILE = 'test_ner_input.json'\n",
    "TRAIN_PATH = '../input/coleridge-bert-models/train_ner.json'\n",
    "VAL_PATH = '../input/coleridge-bert-models/train_ner.json'\n",
    "\n",
    "PREDICTION_SAVE_PATH = './pred'\n",
    "PREDICTION_FILE = 'test_predictions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065327,
     "end_time": "2021-05-23T15:46:07.776946",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.711619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transform data to NER format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061598,
     "end_time": "2021-05-23T15:46:07.902381",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.840783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Group by publication, training labels should have the same form as expected output.\n",
    "\n",
    "딕셔너리에 토큰 : 태그 형식으로 바꾸어 넣는듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:08.045448Z",
     "iopub.status.busy": "2021-05-23T15:46:08.044328Z",
     "iopub.status.idle": "2021-05-23T15:46:08.748629Z",
     "shell.execute_reply": "2021-05-23T15:46:08.749433Z",
     "shell.execute_reply.started": "2021-05-23T15:23:55.796074Z"
    },
    "papermill": {
     "duration": 0.782993,
     "end_time": "2021-05-23T15:46:08.749683",
     "exception": false,
     "start_time": "2021-05-23T15:46:07.966690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. grouped training rows: 14316\n"
     ]
    }
   ],
   "source": [
    "train = train.groupby('Id').agg({\n",
    "    'pub_title': 'first',\n",
    "    'dataset_title': '|'.join,\n",
    "    'dataset_label': '|'.join,\n",
    "    'cleaned_label': '|'.join\n",
    "}).reset_index()\n",
    "\n",
    "print(f'No. grouped training rows: {len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:08.883118Z",
     "iopub.status.busy": "2021-05-23T15:46:08.882128Z",
     "iopub.status.idle": "2021-05-23T15:46:08.887486Z",
     "shell.execute_reply": "2021-05-23T15:46:08.889222Z",
     "shell.execute_reply.started": "2021-05-23T15:23:56.263194Z"
    },
    "papermill": {
     "duration": 0.078081,
     "end_time": "2021-05-23T15:46:08.889475",
     "exception": false,
     "start_time": "2021-05-23T15:46:08.811394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_training_text(txt):\n",
    "    \"\"\"\n",
    "    similar to the default clean_text function but without lowercasing.\n",
    "    \"\"\"\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n",
    "\n",
    "\n",
    "def shorten_sentences(sentences):  #문장이 max len 넘을 경우에 처리 방법\n",
    "    short_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        if len(words) > MAX_LENGTH:\n",
    "            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n",
    "                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n",
    "        else:\n",
    "            short_sentences.append(sentence)\n",
    "    return short_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:08.999379Z",
     "iopub.status.busy": "2021-05-23T15:46:08.988715Z",
     "iopub.status.idle": "2021-05-23T15:46:09.030231Z",
     "shell.execute_reply": "2021-05-23T15:46:09.030801Z",
     "shell.execute_reply.started": "2021-05-23T15:23:56.275881Z"
    },
    "papermill": {
     "duration": 0.096902,
     "end_time": "2021-05-23T15:46:09.030967",
     "exception": false,
     "start_time": "2021-05-23T15:46:08.934065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of sentences: 2283\n"
     ]
    }
   ],
   "source": [
    "test_rows = [] # test data in NER format\n",
    "paper_length = [] # store the number of sentences each paper has\n",
    "\n",
    "for paper_id in sample_submission['Id']:\n",
    "    # load paper\n",
    "    paper = papers[paper_id]\n",
    "    \n",
    "    # extract sentences\n",
    "    sentences = [clean_training_text(sentence) for section in paper \n",
    "                 for sentence in section['text'].split('.')]                \n",
    "    sentences = shorten_sentences(sentences) # make sentences short\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n",
    "    #sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study','from'])]  #단어들 포함하는 문장이 라벨 7-80% 담당\n",
    "        \n",
    "    # collect all sentences in json\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split()\n",
    "        dummy_tags = ['O']*len(sentence_words)\n",
    "        test_rows.append({'tokens' : sentence_words, 'tags' : dummy_tags})\n",
    "    \n",
    "    # track which sentence belongs to which data point\n",
    "    paper_length.append(len(sentences))\n",
    "    \n",
    "print(f'total number of sentences: {len(test_rows)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036902,
     "end_time": "2021-05-23T15:46:09.105990",
     "exception": false,
     "start_time": "2021-05-23T15:46:09.069088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "결국은 세어보려고 두가지 방법으로 묶어본거네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037975,
     "end_time": "2021-05-23T15:46:09.181225",
     "exception": false,
     "start_time": "2021-05-23T15:46:09.143250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Do predict and collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:09.262048Z",
     "iopub.status.busy": "2021-05-23T15:46:09.261030Z",
     "iopub.status.idle": "2021-05-23T15:46:09.265256Z",
     "shell.execute_reply": "2021-05-23T15:46:09.264714Z",
     "shell.execute_reply.started": "2021-05-23T15:23:56.344049Z"
    },
    "papermill": {
     "duration": 0.046843,
     "end_time": "2021-05-23T15:46:09.265389",
     "exception": false,
     "start_time": "2021-05-23T15:46:09.218546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_PATH\"] = f\"{PRETRAINED_PATH}\"\n",
    "os.environ[\"TRAIN_FILE\"] = f\"{TRAIN_PATH}\"\n",
    "os.environ[\"VALIDATION_FILE\"] = f\"{VAL_PATH}\"\n",
    "os.environ[\"TEST_FILE\"] = f\"{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}\"\n",
    "os.environ[\"OUTPUT_DIR\"] = f\"{PREDICTION_SAVE_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:09.361928Z",
     "iopub.status.busy": "2021-05-23T15:46:09.359016Z",
     "iopub.status.idle": "2021-05-23T15:46:10.138774Z",
     "shell.execute_reply": "2021-05-23T15:46:10.138032Z",
     "shell.execute_reply.started": "2021-05-23T15:23:56.355416Z"
    },
    "papermill": {
     "duration": 0.836426,
     "end_time": "2021-05-23T15:46:10.139016",
     "exception": false,
     "start_time": "2021-05-23T15:46:09.302590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy my_seqeval.py to the working directory because the input directory is non-writable\n",
    "!cp /kaggle/input/coleridge-packages/my_seqeval.py ./\n",
    "\n",
    "# make necessart directories and files\n",
    "os.makedirs(TEST_INPUT_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:10.219972Z",
     "iopub.status.busy": "2021-05-23T15:46:10.219330Z",
     "iopub.status.idle": "2021-05-23T15:46:10.224185Z",
     "shell.execute_reply": "2021-05-23T15:46:10.223609Z",
     "shell.execute_reply.started": "2021-05-23T15:28:18.709804Z"
    },
    "papermill": {
     "duration": 0.04768,
     "end_time": "2021-05-23T15:46:10.224328",
     "exception": false,
     "start_time": "2021-05-23T15:46:10.176648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bert_predict():\n",
    "    !python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n",
    "    --model_name_or_path \"$MODEL_PATH\" \\\n",
    "    --train_file \"$TRAIN_FILE\" \\\n",
    "    --validation_file \"$VALIDATION_FILE\" \\\n",
    "    --test_file \"$TEST_FILE\" \\\n",
    "    --output_dir \"$OUTPUT_DIR\" \\\n",
    "    --report_to 'none' \\\n",
    "    --seed 123 \\\n",
    "    --do_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:46:10.325164Z",
     "iopub.status.busy": "2021-05-23T15:46:10.311706Z",
     "iopub.status.idle": "2021-05-23T15:47:56.260097Z",
     "shell.execute_reply": "2021-05-23T15:47:56.259444Z",
     "shell.execute_reply.started": "2021-05-23T15:28:21.629216Z"
    },
    "papermill": {
     "duration": 105.998336,
     "end_time": "2021-05-23T15:47:56.260293",
     "exception": false,
     "start_time": "2021-05-23T15:46:10.261957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './pred': No such file or directory\r\n",
      "2021-05-23 15:46:16.649081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-a88a7e8a1ba3f988/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\r\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a88a7e8a1ba3f988/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\r\n",
      "[INFO|configuration_utils.py:470] 2021-05-23 15:47:15,262 >> loading configuration file ../input/coleridge-bert-models/output/config.json\r\n",
      "[INFO|configuration_utils.py:508] 2021-05-23 15:47:15,263 >> Model config BertConfig {\r\n",
      "  \"_name_or_path\": \"bert-base-cased\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"BertForTokenClassification\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"finetuning_task\": \"ner\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"model_type\": \"bert\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"position_embedding_type\": \"absolute\",\r\n",
      "  \"transformers_version\": \"4.5.0.dev0\",\r\n",
      "  \"type_vocab_size\": 2,\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 28996\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|configuration_utils.py:470] 2021-05-23 15:47:15,264 >> loading configuration file ../input/coleridge-bert-models/output/config.json\r\n",
      "[INFO|configuration_utils.py:508] 2021-05-23 15:47:15,265 >> Model config BertConfig {\r\n",
      "  \"_name_or_path\": \"bert-base-cased\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"BertForTokenClassification\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"finetuning_task\": \"ner\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"model_type\": \"bert\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"position_embedding_type\": \"absolute\",\r\n",
      "  \"transformers_version\": \"4.5.0.dev0\",\r\n",
      "  \"type_vocab_size\": 2,\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 28996\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:1637] 2021-05-23 15:47:15,269 >> Didn't find file ../input/coleridge-bert-models/output/tokenizer.json. We won't load it.\r\n",
      "[INFO|tokenization_utils_base.py:1637] 2021-05-23 15:47:15,270 >> Didn't find file ../input/coleridge-bert-models/output/added_tokens.json. We won't load it.\r\n",
      "[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:47:15,274 >> loading file ../input/coleridge-bert-models/output/vocab.txt\r\n",
      "[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:47:15,274 >> loading file None\r\n",
      "[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:47:15,274 >> loading file None\r\n",
      "[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:47:15,274 >> loading file ../input/coleridge-bert-models/output/special_tokens_map.json\r\n",
      "[INFO|tokenization_utils_base.py:1700] 2021-05-23 15:47:15,274 >> loading file ../input/coleridge-bert-models/output/tokenizer_config.json\r\n",
      "[INFO|modeling_utils.py:1049] 2021-05-23 15:47:15,367 >> loading weights file ../input/coleridge-bert-models/output/pytorch_model.bin\r\n",
      "[INFO|modeling_utils.py:1167] 2021-05-23 15:47:25,844 >> All model checkpoint weights were used when initializing BertForTokenClassification.\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:1176] 2021-05-23 15:47:25,844 >> All the weights of BertForTokenClassification were initialized from the model checkpoint at ../input/coleridge-bert-models/output.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\r\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.59ba/s]\r\n",
      "[INFO|trainer.py:485] 2021-05-23 15:47:35,364 >> The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens.\r\n",
      "[INFO|trainer.py:1817] 2021-05-23 15:47:35,366 >> ***** Running Prediction *****\r\n",
      "[INFO|trainer.py:1818] 2021-05-23 15:47:35,366 >>   Num examples = 2283\r\n",
      "[INFO|trainer.py:1819] 2021-05-23 15:47:35,366 >>   Batch size = 8\r\n",
      "100%|████████████████████████████████████████▊| 285/286 [00:16<00:00, 17.78it/s]/opt/conda/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\r\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\r\n",
      "[INFO|trainer_pt_utils.py:735] 2021-05-23 15:47:55,064 >> ***** test metrics *****\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,064 >>   init_mem_cpu_alloc_delta  =     1458MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   init_mem_cpu_peaked_delta =      300MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   init_mem_gpu_alloc_delta  =      411MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   init_mem_gpu_peaked_delta =        0MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_accuracy             =     0.9991\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_f1                   =        0.0\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_loss                 =     0.0048\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_mem_cpu_alloc_delta  =       84MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_mem_cpu_peaked_delta =        0MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_mem_gpu_alloc_delta  =        0MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,065 >>   test_mem_gpu_peaked_delta =       39MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,066 >>   test_precision            =        0.0\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,066 >>   test_recall               =        0.0\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,066 >>   test_runtime              = 0:00:19.29\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-05-23 15:47:55,066 >>   test_samples_per_second   =    118.323\r\n",
      "100%|█████████████████████████████████████████| 286/286 [00:18<00:00, 15.28it/s]\r\n"
     ]
    }
   ],
   "source": [
    "#BERT Training 실행하는 부분 !!\n",
    "\n",
    "bert_outputs = []\n",
    "\n",
    "for batch_begin in range(0, len(test_rows), PREDICT_BATCH):\n",
    "    # write data rows to input file\n",
    "    with open(f'{TEST_INPUT_SAVE_PATH}/{TEST_NER_DATA_FILE}', 'w') as f:\n",
    "        for row in test_rows[batch_begin:batch_begin+PREDICT_BATCH]:\n",
    "            json.dump(row, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # remove output dir\n",
    "    !rm -r \"$OUTPUT_DIR\"\n",
    "    \n",
    "    # do predict\n",
    "    bert_predict()\n",
    "    \n",
    "    # read predictions\n",
    "    with open(f'{PREDICTION_SAVE_PATH}/{PREDICTION_FILE}') as f:\n",
    "        this_preds = f.read().split('\\n')[:-1]\n",
    "        bert_outputs += [pred.split() for pred in this_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.089797,
     "end_time": "2021-05-23T15:47:56.443741",
     "exception": false,
     "start_time": "2021-05-23T15:47:56.353944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Restore Dataset labels from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:56.628685Z",
     "iopub.status.busy": "2021-05-23T15:47:56.627734Z",
     "iopub.status.idle": "2021-05-23T15:47:56.631542Z",
     "shell.execute_reply": "2021-05-23T15:47:56.630877Z",
     "shell.execute_reply.started": "2021-05-23T15:30:08.568705Z"
    },
    "papermill": {
     "duration": 0.100104,
     "end_time": "2021-05-23T15:47:56.631679",
     "exception": false,
     "start_time": "2021-05-23T15:47:56.531575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get test sentences\n",
    "test_sentences = [row['tokens'] for row in test_rows]\n",
    "\n",
    "del test_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:56.836993Z",
     "iopub.status.busy": "2021-05-23T15:47:56.835920Z",
     "iopub.status.idle": "2021-05-23T15:47:56.839539Z",
     "shell.execute_reply": "2021-05-23T15:47:56.839002Z",
     "shell.execute_reply.started": "2021-05-23T15:30:08.581026Z"
    },
    "papermill": {
     "duration": 0.118673,
     "end_time": "2021-05-23T15:47:56.839665",
     "exception": false,
     "start_time": "2021-05-23T15:47:56.720992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_dataset_labels = [] # store all dataset labels for each publication\n",
    "\n",
    "for length in paper_length:\n",
    "    labels = set()\n",
    "    for sentence, pred in zip(test_sentences[:length], bert_outputs[:length]):\n",
    "        curr_phrase = ''\n",
    "        for word, tag in zip(sentence, pred):\n",
    "            if tag == 'B': # start a new phrase\n",
    "                if curr_phrase:\n",
    "                    labels.add(curr_phrase)\n",
    "                    curr_phrase = ''\n",
    "                curr_phrase = word\n",
    "            elif tag == 'I' and curr_phrase: # continue the phrase\n",
    "                curr_phrase += ' ' + word\n",
    "            else: # end last phrase (if any)\n",
    "                if curr_phrase:\n",
    "                    labels.add(curr_phrase)\n",
    "                    curr_phrase = ''\n",
    "        # check if the label is the suffix of the sentence\n",
    "        if curr_phrase:\n",
    "            labels.add(curr_phrase)\n",
    "            curr_phrase = ''\n",
    "    \n",
    "    # record dataset labels for this publication\n",
    "    bert_dataset_labels.append(labels)\n",
    "    \n",
    "    del test_sentences[:length], bert_outputs[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:57.027422Z",
     "iopub.status.busy": "2021-05-23T15:47:57.026291Z",
     "iopub.status.idle": "2021-05-23T15:47:57.031618Z",
     "shell.execute_reply": "2021-05-23T15:47:57.031022Z",
     "shell.execute_reply.started": "2021-05-23T15:30:08.611565Z"
    },
    "papermill": {
     "duration": 0.104015,
     "end_time": "2021-05-23T15:47:57.031759",
     "exception": false,
     "start_time": "2021-05-23T15:47:56.927744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Alzheimer s Disease Neuroimaging Initiative ADNI'},\n",
       " {'Trends in International Mathematics and Science Study'},\n",
       " {'SLOSH model'},\n",
       " {'Rural Urban Continuum Codes'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_dataset_labels   #문제는 이것들이 다 베이스라인에 이미 있는 것들... => 그래서 점수 똑같이 나오는거네.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.091179,
     "end_time": "2021-05-23T15:47:57.212728",
     "exception": false,
     "start_time": "2021-05-23T15:47:57.121549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "data, study, from 포함되는 문장만 뽑는거 줄이는 코드 없애니까 맨 마지막 id 부분이 BERT에서도 뭔가가 나오네..\n",
    "\n",
    "문장 max 길이 256으로 늘려봐도 결과 똑같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.094478,
     "end_time": "2021-05-23T15:47:57.398625",
     "exception": false,
     "start_time": "2021-05-23T15:47:57.304147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Filter based on Jaccard score and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:57.591202Z",
     "iopub.status.busy": "2021-05-23T15:47:57.590234Z",
     "iopub.status.idle": "2021-05-23T15:47:57.593937Z",
     "shell.execute_reply": "2021-05-23T15:47:57.593417Z",
     "shell.execute_reply.started": "2021-05-23T15:30:08.635957Z"
    },
    "papermill": {
     "duration": 0.104663,
     "end_time": "2021-05-23T15:47:57.594095",
     "exception": false,
     "start_time": "2021-05-23T15:47:57.489432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    l1 = s1.split(\" \")\n",
    "    l2 = s2.split(\" \")    \n",
    "    intersection = len(list(set(l1).intersection(l2)))\n",
    "    union = (len(l1) + len(l2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "filtered_bert_labels = []\n",
    "\n",
    "for labels in bert_dataset_labels:\n",
    "    filtered = []\n",
    "    \n",
    "    for label in sorted(labels, key=len):\n",
    "        label = clean_text(label)\n",
    "        if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered):\n",
    "            filtered.append(label)\n",
    "    \n",
    "    filtered_bert_labels.append('|'.join(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:57.783470Z",
     "iopub.status.busy": "2021-05-23T15:47:57.782326Z",
     "iopub.status.idle": "2021-05-23T15:47:57.787647Z",
     "shell.execute_reply": "2021-05-23T15:47:57.787116Z",
     "shell.execute_reply.started": "2021-05-23T15:34:38.945543Z"
    },
    "papermill": {
     "duration": 0.102392,
     "end_time": "2021-05-23T15:47:57.787783",
     "exception": false,
     "start_time": "2021-05-23T15:47:57.685391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alzheimer s disease neuroimaging initiative adni',\n",
       " 'trends in international mathematics and science study',\n",
       " 'slosh model',\n",
       " 'rural urban continuum codes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_bert_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090285,
     "end_time": "2021-05-23T15:47:57.968864",
     "exception": false,
     "start_time": "2021-05-23T15:47:57.878579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Aggregate final predictions and write submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:58.156371Z",
     "iopub.status.busy": "2021-05-23T15:47:58.155396Z",
     "iopub.status.idle": "2021-05-23T15:47:58.159276Z",
     "shell.execute_reply": "2021-05-23T15:47:58.158623Z",
     "shell.execute_reply.started": "2021-05-23T15:33:27.082843Z"
    },
    "papermill": {
     "duration": 0.100458,
     "end_time": "2021-05-23T15:47:58.159439",
     "exception": false,
     "start_time": "2021-05-23T15:47:58.058981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "for literal_match, bert_pred in zip(literal_preds, filtered_bert_labels):\n",
    "    if literal_match:\n",
    "        #final_predictions.append(literal_match)\n",
    "        pass\n",
    "    else:\n",
    "        final_predictions.append(bert_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:58.352936Z",
     "iopub.status.busy": "2021-05-23T15:47:58.351889Z",
     "iopub.status.idle": "2021-05-23T15:47:58.361664Z",
     "shell.execute_reply": "2021-05-23T15:47:58.361149Z",
     "shell.execute_reply.started": "2021-05-23T15:34:50.753323Z"
    },
    "papermill": {
     "duration": 0.110821,
     "end_time": "2021-05-23T15:47:58.361794",
     "exception": false,
     "start_time": "2021-05-23T15:47:58.250973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>alzheimer s disease neuroimaging initiative adni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>trends in international mathematics and scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>slosh model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>rural urban continuum codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "1  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2  3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                    PredictionString  \n",
       "0   alzheimer s disease neuroimaging initiative adni  \n",
       "1  trends in international mathematics and scienc...  \n",
       "2                                        slosh model  \n",
       "3                        rural urban continuum codes  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['PredictionString'] = filtered_bert_labels#final_predictions\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T15:47:58.550746Z",
     "iopub.status.busy": "2021-05-23T15:47:58.549706Z",
     "iopub.status.idle": "2021-05-23T15:47:58.698229Z",
     "shell.execute_reply": "2021-05-23T15:47:58.697532Z",
     "shell.execute_reply.started": "2021-05-23T15:41:53.874906Z"
    },
    "papermill": {
     "duration": 0.243875,
     "end_time": "2021-05-23T15:47:58.698377",
     "exception": false,
     "start_time": "2021-05-23T15:47:58.454502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08913,
     "end_time": "2021-05-23T15:47:58.879721",
     "exception": false,
     "start_time": "2021-05-23T15:47:58.790591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 305.942186,
   "end_time": "2021-05-23T15:47:59.780996",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-23T15:42:53.838810",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
